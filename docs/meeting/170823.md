# 170823 

## 시나리오

1. 시나리오 1
```
목표 1. 글루시스 SATA마모되는 과정의 로그 확인
목표 2. 특정 디바이스를 임의로 뽑았을 때의 로그 확인
(목표 3. 이미 고장 난 디바이스를 통해 작업했을 때의 로그 확인)
1번 노드 : SATA 3 (정상 2, 글루시스 1)
2번 노드 : SATA 3 (정상 2, 글루시스 1)
3번 노드 : SATA 3 (정상 1, 글루시스 2) 
버컷 1 (목표 1) : 글루시스 HDD들
  - 버킷 1-1 2개 (1번노드, 3번노드)
  - 버킷 1-2 2개 (2번노드, 3번노드)
버킷 2 (목표 2) : 우리 HDD들
  - 버킷 2-1 2개 (1번노드, 2번노드)
  - 버킷 2-2 3개 (1, 2, 3 노드)
replica 수 2개

저질러야 하는 일
1. 버컷 1-1, 1-2 에 물린 VM에 I/O 엄청 때리기
2. 버킷 2-1에 있는 HDD하나 뽑기, 두개 다 뽑기

클라이언트에 올라갈 VM 수 2개씩 총 4개
클라이언트 1
  VM 1-1 : 버킷 1-1
  VM 1-2 : 버킷 2-1(디바이스 뽑기)
클라이언트 2
  VM 2-1 : 버킷 1-2
  VM 2-2 : 버킷 2-2

SATA 연장 케이블은 2개 필요
```

## 학습
* influxdb 접근해서 데이터 읽어온 후에 학습

## 예측
* kafka에 접근해서 예측

## 할 일
* 파이썬 공부,  소스 분석(Failure_Prediction/v0.2 - client.py, collector.py 제외) - 형준, 성민 ( ~8/30, ~9/10)
* 오픈스택 인 액션 - 성민 ( 키스톤만 보면돼, ~9/10) 
* 센터 서버에 sas 꽂아서 동작하는지 확인 - 승호
* sas 컨트롤러, sata 케이블 구매 - 승호
* influxdb python api 정리 - 영우
  - 테이블당 메트릭 하나 들어있는데, 이거 dataframe, np 로 변형 구현해야 되는데, 프레임워크에서 동작 가능하게, op type 'TI'에 들어가는 function이야. 학습데이터를 읽는 연산.
* kafka-python api 정리 - 영우
 - 카프카에서 읽어서 dataframe으로 변형
* ceph plug-in metric 정리 - 승호
 - 관련되어 보이는 거 다 추리고, sas를 통해 얻은 데이터로 2차적으로 추출.
sdf
