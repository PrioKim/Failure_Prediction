# 170817 

## keystone

* word file 

## kafka
* Msg queue, app : app이 통신을 하기를 원해
* 다이렉트 통신은 무리가 있어, 한쪽이 produce 하는 속도랑, consume 하는 속도가 다름. produce 정보의 양과 consume 정보의 양이 달라.
* queue를 둬서 이걸 해자는 거야. 
* 1:1로 동작하는 방식, consume하면 데이터가 사라짐
* n:n으로 동작하는 방식, consume하면 안사라지고 언제사라질까?
* topic, partition, Broker.
* kafka-python, monasca가 데이터를 만들어서 kafka 집어넣는데 이걸 우리가 어떻게 꺼내다가 쓸건가...? 예제를 가지고 해보니까 잘 안되...
* monasaca-agent -> monasca-api(producer) -> kafka -> monasca-persister(consumer) -> influxdb
* monasca-persister를 분석하면 되. 그대로 하면되.

## monasca-persister
* 분석중... 
* metric 하나당 하나의 테이블인데 학습시에 어떻게 데이터에 접근할 것 인가.
  * 어째든 우리는 학습데이터, influxdb에 저장되있는 필요한 데이터들을 select해서 우리가 원하는 형태로 재가공하는 법
  * kafka에서 우리가 데이터를 꺼내와서 학습할 데이터의 형태로 변환해서 influxdb든 file이든 저장하는거
  * monasca-agent에서 보낼때 데이터 형태를 바꿔보낼까??

* 예측시에는 무조건 kafka에서 꺼내와서 이용함

## Ceph
* 정리해서 다시 말해주셈. 너무 어려움


## Deploy
* Ceph 정리 후, 가능

## Have to do.
* monasca-persister -> 분석 (영우)
* python-kafka 이용법 (형준)
* ceph 정리 해주세요 + ceph 설치 구성 (승호)
* ceph metric 정리(ceph 머리가 다 들어있어야 가능할 듯) - 미정
* linux 책 끝내기, 오픈스택 형준이가 했던거 배우기 (성민)
